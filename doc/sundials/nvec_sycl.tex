\section{The NVECTOR\_SYCL implementation}\label{ss:nvec_sycl}

The {\nvecsycl} module is an experimental {\nvector} implementation using the
\href{https://www.khronos.org/sycl/}{\sycl} abstraction layer.  At present the
only supported {\sycl} compiler is the DPC++ (Intel oneAPI) compiler. This module
allows for {\sundials} vector kernels to run on Intel GPU devices. The module is
intended for users who are already familiar with {\sycl} and GPU programming.

The vector content layout is as follows:
\begin{verbatim}
struct _N_VectorContent_Sycl
{
   sunindextype       length;
   booleantype        own_exec;
   booleantype        own_helper;
   SUNMemory          host_data;
   SUNMemory          device_data;
   SUNSyclExecPolicy* stream_exec_policy;
   SUNSyclExecPolicy* reduce_exec_policy;
   SUNMemoryHelper    mem_helper;
   sycl::queue*       queue;
   void*              priv; /* 'private' data */
};

typedef struct _N_VectorContent_Sycl *N_VectorContent_Sycl;
\end{verbatim}
The content members are the vector length (size), boolean flags that indicate
if the vector owns the execution policies and memory helper objects (i.e., it is
in charge of freeing the objects), \id{SUNMemory} objects for the vector data on
the host and device, pointers to execution policies that control how streaming
and reduction kernels are launched, a \id{SUNMemoryHelper} for performing memory
operations, the {\sycl} queue, and a private data structure which holds additional
members that should not be accessed directly.

When instantiated with \id{N\_VNew\_Sycl()}, the underlying data will be
allocated on both the host and the device. Alternatively, a user can provide
host and device data arrays by using the \id{N\_VMake\_Sycl()} constructor.
To use managed (shared) memory, the constructors \id{N\_VNewManaged\_Sycl()} and
\\ \noindent
\id{N\_VMakeManaged\_Sycl()} are provided. Additionally, a user-defined
\id{SUNMemoryHelper} for allocating/freeing data can be provided with the
constructor \id{N\_VNewWithMemHelp\_Sycl()}. Details on each of these
constructors are provided below.

The header file to include when using this is \id{nvector\_sycl.h}. The
installed module library to link to is \id{libsundials\_nvecsycl.lib}. The
extension \id{.lib} is typically \id{.so} for shared libraries \id{.a} for
static libraries.

% ====================================================================
\subsection{NVECTOR\_SYCL functions}
\label{ss:nvec_sycl_functions}
% ====================================================================

The {\nvecsycl} module implementations of all vector operations listed in the
sections in Tables \ref{ss:nvecops}, \ref{ss:nvecfusedops},
\ref{ss:nvecarrayops}, and \ref{ss:nveclocalops}, except for
\id{N\_VDotProdMulti}, \id{N\_VWrmsNormVectorArray}, and \\ \noindent
\id{N\_VWrmsNormMaskVectorArray} as support for arrays of reduction vectors is
not yet supported. These function will be added to the {\nvecsycl}
implementation in the future. The names of vector operations are obtained from
those in the aforementioned sections by appending the suffix \id{\_Sycl} (e.g.,
\id{N\_VDestroy\_Sycl}).

Additionally, the {\nvecsycl} module provides the following user-callable
constructors for creating a new {\nvecsycl}:

%%--------------------------------------
\sunmodfun{N\_VNew\_Sycl}
{
  This function creates and allocates memory for a {\sycl} \id{N\_Vector}.
  The vector data array is allocated on both the host and device.
}
{
  N\_Vector N\_VNew\_Sycl(sunindextype length, sycl::queue* Q)
}
%%--------------------------------------
\sunmodfun{N\_VNewManaged\_Sycl}
{
  This function creates and allocates memory for a {\sycl} \id{N\_Vector}.
  The vector data array is allocated in managed memory.
}
{
  N\_Vector N\_VNewManaged\_Sycl(sunindextype length, sycl::queue* Q)
}
%%--------------------------------------
\sunmodfun{N\_VMake\_Sycl}
{
  This function creates an {\nvecsycl} with user-supplied vector data arrays
  \id{h\_vdata} and \id{d\_vdata}. This function does not allocate memory for
  data itself.
}
{
  N\_Vector N\_VMake\_Sycl(sunindextype length, realtype *h\_data,
  \newlinefill{N\_Vector N\_VMake\_Sycl} realtype *dev\_data, sycl::queue* Q)
}
%%--------------------------------------
\sunmodfun{N\_VMakeManaged\_Sycl}
{
  This function creates an {\nvecsycl} with a user-supplied managed memory data
  array. This function does not allocate memory for data itself.
}
{
  N\_Vector N\_VMakeManaged\_Sycl(sunindextype length, realtype *vdata,
  \newlinefill{N\_Vector N\_VMakeManaged\_Sycl} sycl::queue* Q)
}
%%--------------------------------------
\sunmodfun{N\_VNewWithMemHelp\_Sycl}
{
  This function creates an {\nvecsycl} which will use the \id{SUNMemoryHelper}
  object to allocate memory. If \id{use\_managed\_memory} is 0, then unmanaged
  memory is used, otherwise managed memory is used.
}
{
  N\_Vector N\_VNewWithMemHelp\_Sycl(sunindextype length,
  \newlinefill{N\_Vector N\_VNewWithMemHelp\_Sycl} booleantype use\_managed\_mem,
  \newlinefill{N\_Vector N\_VNewWithMemHelp\_Sycl} SUNMemoryHelper helper, sycl::queue* Q);
}

%%--------------------------------------
\sunmodfun{N\_VNewEmpty\_Sycl}
{
  This function creates a new {\nvecsycl} where the members of the content
  structure have not been allocated. This utility function is used by the
  other constructors to create a new vector.
}
{
  N\_Vector N\_VNewEmpty\_Sycl()
}
%%--------------------------------------

The following user-callable functions are provided for accessing the vector data
arrays on the host and device and copying data between the two memory spaces.
Note the generic {\nvector} operations \id{N\_VGetArrayPointer()} and
\id{N\_VSetArrayPointer()} are mapped to the corresponding \id{HostArray}
functions given below. To ensure memory coherency, a user will need to call the
\id{CopyTo} or \id{CopyFrom} functions as necessary to transfer data between the
host and device, unless managed (shared) memory is used.

%%--------------------------------------
\sunmodfun{N\_VGetHostArrayPointer\_Sycl}
{
  This function returns a pointer to the vector data on the host.
}
{
  realtype *N\_VGetHostArrayPointer\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VGetDeviceArrayPointer\_Sycl}
{
  This function returns a pointer to the vector data on the device.
}
{
  realtype *N\_VGetDeviceArrayPointer\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VSetHostArrayPointer\_Sycl}
{
  This function sets the pointer to the vector data on the host.
  The existing pointer \textit{will not} be freed first.
}
{
  realtype *N\_VSetHostArrayPointer\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VSetDeviceArrayPointer\_Sycl}
{
  This function sets pointer to the vector data on the device.
  The existing pointer \textit{will not} be freed first.
}
{
  realtype *N\_VSetDeviceArrayPointer\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VCopyToDevice\_Sycl}
{
 This function copies host vector data to the device.
}
{
 realtype *N\_VCopyToDevice\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VCopyFromDevice\_Sycl}
{
  This function copies vector data from the device to the host.
}
{
  realtype *N\_VCopyFromDevice\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VIsManagedMemory\_Sycl}
{
  This function returns a boolean flag indicating if the vector
  data is allocated in managed memory or not.
}
{
  booleantype *N\_VIsManagedMemory\_Sycl(N\_Vector v)
}
%%--------------------------------------

The following user-callable function is provided to set the execution policies
for how {\sycl} kernels are launched on a device.

\sunmodfun{N\_VSetKernelExecPolicy\_Sycl}
{
  This function sets the execution policies which control the kernel parameters
  utilized when launching the streaming and reduction kernels. By default the
  vector is setup to use the \id{SUNSyclThreadDirectExecPolicy} and
  \id{SUNSyclBlockReduceExecPolicy}. See Section \ref{ss:sunsyclexecpolicy}
  below for more information about the \id{SUNSyclExecPolicy} class.

  \textbf{Note:} All vectors used in a single instance of a {\sundials} package
  must use the same execution policy. It is \textbf{strongly recommended} that
  this function is called immediately after constructing the vector, and any
  subsequent vector be created by cloning to ensure consistent execution
  policies across vectors.
}
{
  int N\_VSetKernelExecPolicy\_Sycl(N\_Vector v,
  \newlinefill{int N\_VSetKernelExecPolicy\_Sycl} SUNSyclExecPolicy *stream\_exec\_policy,
  \newlinefill{int N\_VSetKernelExecPolicy\_Sycl} SUNSyclExecPolicy *reduce\_exec\_policy)
}


The following user-callable functions are provided to print the host vector data
array. Unless managed memory is used, a user may need to call
\id{N\_VCopyFromDevice\_Sycl()} to ensure consistency between the host and
device array.
%%--------------------------------------
\sunmodfun{N\_VPrint\_Sycl}
{
  This function prints the host data of a {\sycl} vector to \id{stdout}.
}
{
  void N\_VPrint\_Sycl(N\_Vector v)
}
%%--------------------------------------
\sunmodfun{N\_VPrintFile\_Sycl}
{
  This function prints the host data of a {\sycl} vector to \id{outfile}.
}
{
  void N\_VPrintFile\_Sycl(N\_Vector v, FILE *outfile)
}
%%--------------------------------------

By default all fused and vector array operations are disabled in the {\nvecsycl}
module. The following additional user-callable routines are provided to
enable or disable fused and vector array operations for a specific vector. To
ensure consistency across vectors it is recommended to first create a vector
with one of the above constructors, enable/disable the desired operations on
that vector with the functions below, and then use this vector in conjunction
\id{N\_VClone} to create any additional vectors. This guarantees the new vectors
will have the same operations enabled/disabled as cloned vectors inherit the
same enable/disable options as the vector they are cloned from while vectors
created by any of the above constructors will have the default settings for the
{\nvecsycl} module.
%%--------------------------------------
\sunmodfun{N\_VEnableFusedOps\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) all fused and
  vector array operations in the {\sycl} vector. The return value is \id{0} for
  success and \id{-1} if the input vector or its \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableFusedOps\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableLinearCombination\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the linear
  combination fused operation in the {\sycl} vector. The return value is \id{0} for
  success and \id{-1} if the input vector or its \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableLinearCombination\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableScaleAddMulti\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the scale and
  add a vector to multiple vectors fused operation in the {\sycl} vector. The
  return value is \id{0} for success and \id{-1} if the input vector or its
  \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableScaleAddMulti\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableLinearSumVectorArray\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the linear sum
  operation for vector arrays in the {\sycl} vector. The return value is \id{0} for
  success and \id{-1} if the input vector or its \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableLinearSumVectorArray\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableScaleVectorArray\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the scale
  operation for vector arrays in the {\sycl} vector. The return value is \id{0} for
  success and \id{-1} if the input vector or its \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableScaleVectorArray\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableConstVectorArray\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the const
  operation for vector arrays in the {\sycl} vector. The return value is \id{0} for
  success and \id{-1} if the input vector or its \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableConstVectorArray\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableScaleAddMultiVectorArray\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the scale and
  add a vector array to multiple vector arrays operation in the {\sycl} vector. The
  return value is \id{0} for success and \id{-1} if the input vector or its
  \id{ops} structure are \id{NULL}.
}
{
  int N\_VEnableScaleAddMultiVectorArray\_Sycl(N\_Vector v, booleantype tf)
}
%%--------------------------------------
\sunmodfun{N\_VEnableLinearCombinationVectorArray\_Sycl}
{
  This function enables (\id{SUNTRUE}) or disables (\id{SUNFALSE}) the linear
  combination operation for vector arrays in the {\sycl} vector. The return value
  is \id{0} for success and \id{-1} if the input vector or its \id{ops} structure
  are \id{NULL}.
}
{
  int N\_VEnableLinearCombinationVectorArray\_Sycl(N\_Vector v,
  \newlinefill{int N\_VEnableLinearCombinationVectorArray\_Sycl}
  booleantype tf)
}
%%
%%------------------------------------
%%
\paragraph{\bf Notes}

\begin{itemize}

\item
  When there is a need to access components of an \id{N\_Vector\_Sycl}, \id{v},
  it is recommended to use \id{N\_VGetDeviceArrayPointer} to access the device
  array or \id{N\_VGetArrayPointer} for the host array. When using managed
  (shared) memory, either function may be used. To ensure memory coherency, a
  user may need to call the \id{CopyTo} or \id{CopyFrom} functions as necessary
  to transfer data between the host and device, unless managed (shared) memory
  is used.

\item
  {\warn}To maximize efficiency, vector operations in the {\nvecsycl} implementation
  that have more than one \id{N\_Vector} argument do not check for
  consistent internal representations of these vectors. It is the user's
  responsibility to ensure that such routines are called with \id{N\_Vector}
  arguments that were all created with the same internal representations.

\end{itemize}

% ====================================================================
\subsection{The SUNSyclExecPolicy Class}
\label{ss:sunsyclexecpolicy}
% ====================================================================

In order to provide maximum flexibility to users, the {\sycl} kernel execution
parameters used by kernels within {\sundials} are defined by objects of the
\id{sundials::SyclExecPolicy} abstract class type (this class can be accessed in
the global namespace as \id{SUNSyclExecPolicy}). Thus, users may provide custom
execution policies that fit the needs of their problem. The
\id{sundials::SyclExecPolicy} is defined in the header file
\id{sundials\_sycl\_policies.hpp}, as follows:

\begin{verbatim}
class SyclExecPolicy
{
public:
   virtual size_t gridSize(size_t numWorkUnits = 0, size_t blockDim = 0) const = 0;
   virtual size_t blockSize(size_t numWorkUnits = 0, size_t gridDim = 0) const = 0;
   virtual SyclExecPolicy* clone() const = 0;
   virtual ~SyclExecPolicy() {}
};
\end{verbatim}

For consistency the function names and behavior mirror the execution policies
for the CUDA and HIP vectors. In the {\sycl} case the \id{blockSize} is the local
work-group range in a one-dimensional \id{nd\_range} (threads per group). The
\id{gridSize} is the number of local work groups so the global work-group range
in a one-dimensional \id{nd\_range} is \id{blockSize * gridSize} (total number of
threads). All vector kernels are written with a many-to-one mapping where work
units (vector elements) are mapped in a round-robin manner across the global
range. As such, the \id{blockSize} and \id{gridSize} can be set to any positive
value.

To define a custom execution policy, a user simply needs to create a class that
inherits from the abstract class and implements the methods. The {\sundials}
provided \\ \noindent
\id{sundials::SyclThreadDirectExecPolicy} (aka in the global namespace
as \\ \noindent
\id{SUNSyclThreadDirectExecPolicy}) class is a good example of a what a custom
execution policy may look like:

\begin{verbatim}
class SyclThreadDirectExecPolicy : public SyclExecPolicy
{
public:
   SyclThreadDirectExecPolicy(const size_t blockDim)
      : blockDim_(blockDim)
   {}

   SyclThreadDirectExecPolicy(const SyclThreadDirectExecPolicy& ex)
      : blockDim_(ex.blockDim_)
   {}

   virtual size_t gridSize(size_t numWorkUnits = 0, size_t blockDim = 0) const
   {
      return (numWorkUnits + blockSize() - 1) / blockSize();
   }

   virtual size_t blockSize(size_t numWorkUnits = 0, size_t gridDim = 0) const
   {
      return blockDim_;
   }

   virtual SyclExecPolicy* clone() const
   {
      return static_cast<SyclExecPolicy*>(new SyclThreadDirectExecPolicy(*this));
   }

private:
   const size_t blockDim_;
};
\end{verbatim}

{\sundials} provides the following execution policies:
\begin{enumerate}
\item \id{SUNSyclThreadDirectExecPolicy(const size\_t blockDim)}
  is for kernels performing streaming operations and maps each work unit
  (vector element) to a work-item (thread). Based on the local work-group range
  (number of threads per group, \id{blockSize}) the number of local work-groups
  (\id{gridSize}) is computed so there are enough work-items in the global
  work-group range ( total number of threads, \id{blockSize * gridSize}) for one
  work unit per work-item (thread).

\item  \id{SUNSyclGridStrideExecPolicy(const size\_t blockDim, const size\_t gridDim)}
  is for kernels performing streaming operations and maps each work unit
  (vector element) to a work-item (thread) in a round-robin manner so the local
  work-group range (number of threads per group, \id{blockSize}) and the number
  of local work-groups (\id{gridSize}) can be set to any positive value. In this
  case the global work-group range (total number of threads,
  \id{blockSize * gridSize}) may be less than the number of work units (vector
  elements).

\item \id{SUNSyclBlockReduceExecPolicy(const size\_t blockDim)}
  is for kernels performing a reduction, the local work-group range (number
  of threads per group, \id{blockSize}) and the number of local work-groups
  (\id{gridSize}) can be set to any positive value or the \id{gridSize} may be
  set to \id{0} in which case the global range is chosen so that there are
  enough threads for at most two work units per work-item.
\end{enumerate}


By default the {\nvecsycl} module uses the \id{SUNSyclThreadDirectExecPolicy}
and \\ \noindent
\id{SUNSyclBlockReduceExecPolicy} where the default \id{blockDim} is
determined by querying the device for the \id{max\_work\_group\_size}. User may
specify different policies by constructing a new \id{SyclExecPolicy} and
attaching it with \id{N\_VSetKernelExecPolicy\_Sycl()}. For example, a policy
that uses 128 work-items (threads) per group can be created and attached like
so:

\begin{verbatim}
N_Vector v = N_VNew_Sycl(length);
SUNSyclThreadDirectExecPolicy thread_direct(128);
SUNSyclBlockReduceExecPolicy  block_reduce(128);
flag = N_VSetKernelExecPolicy_Sycl(v, &thread_direct, &block_reduce);
\end{verbatim}

These default policy objects can be reused for multiple {\sundials} data structures
(e.g. a \id{SUNMatrix} and an \id{N\_Vector}) since they do not hold any
modifiable state information.
